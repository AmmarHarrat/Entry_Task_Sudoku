{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> pre-processing and preparing the train data </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<p> \n",
    "    <i>\n",
    "     <ul>\n",
    "  <li>In this phase we are going to do an image processing task</li>\n",
    "  <li>first,we have to split each sudoku puzzle image in our train directory to 81 cells (81 sub images) and append each      digit's image to a list.</li>\n",
    "  <li>At the end of this phase we get a list of digit's images that should be used for training, for example if  the number of         the Training images is 150 we get a list with 150 * 81 = 12150 digit's image</li>\n",
    "</ul>\n",
    "    </i>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions rectify and build_train_data are responsible for splitting the sudoku puzzle to  to cells (sub images) each cell contains one digit of the puzzle\n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "import pytesseract\n",
    "from skimage.segmentation import clear_border\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def rectify(h):\n",
    "        h = h.reshape((4,2))\n",
    "        hnew = np.zeros((4,2),dtype = np.float32)\n",
    "\n",
    "        add = h.sum(1)\n",
    "        hnew[0] = h[np.argmin(add)]\n",
    "        hnew[2] = h[np.argmax(add)]\n",
    "\n",
    "        diff = np.diff(h,axis = 1)\n",
    "        hnew[1] = h[np.argmin(diff)]\n",
    "        hnew[3] = h[np.argmax(diff)]\n",
    "\n",
    "        return hnew\n",
    "\n",
    "# detect  each puzzle and split it into 81 sub images (corresponds to each digit in the cell) \n",
    "\n",
    "def build_train_data(path : str):    \n",
    "    \n",
    "    dirs = os.listdir( path ) # the path of  directory which contains all the training images\n",
    "    liste4 = []\n",
    "       \n",
    "    for file in dirs:\n",
    "    \n",
    "            img=cv2.imread(os.path.join(path,file))\n",
    "            if (img.shape[0] > 400 ):\n",
    "                img = img = cv2.resize(img,(300,300))\n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            gray = cv2.GaussianBlur(gray,(5,5),0)\n",
    "            thresh = cv2.adaptiveThreshold(gray,255,1,1,11,2)\n",
    "\n",
    "\n",
    "            contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            biggest = None\n",
    "            max_area = 0\n",
    "            for i in contours:\n",
    "                area = cv2.contourArea(i)\n",
    "                if area > 100:\n",
    "                        peri = cv2.arcLength(i,True)\n",
    "                        approx = cv2.approxPolyDP(i,0.02*peri,True)\n",
    "                        if area > max_area and len(approx)==4:\n",
    "                                biggest = approx\n",
    "                                max_area = area\n",
    "            cv2.drawContours(img, biggest, -1, (0,255,0), 8)\n",
    "\n",
    "\n",
    "\n",
    "            biggest=rectify(biggest)\n",
    "\n",
    "            h = np.array([ [0,0],[449,0],[449,449],[0,449] ],np.float32)\n",
    "            retval = cv2.getPerspectiveTransform(biggest,h)\n",
    "            thresh = cv2.adaptiveThreshold(gray,255,1,1,11,2)\n",
    "\n",
    "            warp = cv2.warpPerspective(thresh,retval,(450,450))  # contains the sudoku puzzle \n",
    "\n",
    "            winX = int(warp.shape[1]/9.0)\n",
    "            winY = int(warp.shape[0]/9.0)\n",
    " \n",
    "            \n",
    "            #loop through all the cells of the sudoku puzzle and append\n",
    "\n",
    "            for y in range(0,warp.shape[0],winY):\n",
    "                  for x in range(0,warp.shape[1],winX):\n",
    "                #slice the cell\n",
    "                        window = warp[y:y+winY,x:x+winX]\n",
    "                #sanity check\n",
    "                        if window.shape[0] != winY or window.shape[1] != winX:\n",
    "                          continue\n",
    "                        clone = warp.copy()\n",
    "                        digit = cv2.resize(window,(28,28))\n",
    "                #clear borders\n",
    "                        digit = clear_border(digit)\n",
    "                        liste4.append(digit)\n",
    "                       \n",
    "            \n",
    "    return liste4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    <i>\n",
    "     <ul>\n",
    "  <li>after getting a list of all the digit's images , now we have to get all the labels for those images ( label in this case is  the value of the digit in each cell )</li>\n",
    "  <li> to get the label of each digit's image in the training data , we have to read each image metadata file (contains the corresponding matrix of each sudoku puzzle image) and append the content of that matrix to a list.</li>\n",
    "  <li>At the end of this phase we get a list of digits, each element of the list is the label(value) of the digit in the corresponding cell of our sudoku puzzles</li>\n",
    "</ul>\n",
    "    </i>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read  labels of our training images \n",
    "def build_get_labels(path : str):\n",
    "    dirs = os.listdir( path )  # path of directory which contains all the metadata files  \n",
    "    liste1 = []\n",
    "    # This would print all the files and directories\n",
    "    for file in dirs:\n",
    "        temp = open(os.path.join(path,file),'r').read().split('\\n')\n",
    "\n",
    "        del temp[0]\n",
    "        del temp[0]\n",
    "        del temp[len(temp)-1]\n",
    "        for i in temp : \n",
    "            liste = i.split(\" \")\n",
    "            for j in liste :\n",
    "                if j != \"\":\n",
    "                    liste1.append(int(j))\n",
    "    return liste1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train contains all the labels of our training images \n",
    "\n",
    "y_train = build_get_labels(\"train/label_image\") \n",
    "\n",
    "#x_train contains all the training images \n",
    "\n",
    "x_train = build_train_data(\"train/train_image\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the training data to feed our model \n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value\n",
    "x_train /= 255\n",
    "\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>build and train the model</h1>\n",
    "\n",
    "<p> \n",
    "   <i> to build our model i used Keras API which is a high-level neural networks API,running on top of TensorFlow,\n",
    "       and is also considered to be the most straightforward TensorFlow API.</i>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size = (3,3), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size = (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "12879/12879 [==============================] - 12s 896us/step - loss: 0.5518 - accuracy: 0.8256\n",
      "Epoch 2/25\n",
      "12879/12879 [==============================] - 11s 856us/step - loss: 0.1753 - accuracy: 0.9581\n",
      "Epoch 3/25\n",
      "12879/12879 [==============================] - 12s 899us/step - loss: 0.1219 - accuracy: 0.9709\n",
      "Epoch 4/25\n",
      "12879/12879 [==============================] - 14s 1ms/step - loss: 0.1036 - accuracy: 0.9765\n",
      "Epoch 5/25\n",
      "12879/12879 [==============================] - 12s 956us/step - loss: 0.0936 - accuracy: 0.9769\n",
      "Epoch 6/25\n",
      "12879/12879 [==============================] - 11s 887us/step - loss: 0.0838 - accuracy: 0.9791\n",
      "Epoch 7/25\n",
      "12879/12879 [==============================] - 12s 926us/step - loss: 0.0811 - accuracy: 0.9788\n",
      "Epoch 8/25\n",
      "12879/12879 [==============================] - 13s 994us/step - loss: 0.0726 - accuracy: 0.9818\n",
      "Epoch 9/25\n",
      "12879/12879 [==============================] - 13s 1ms/step - loss: 0.0652 - accuracy: 0.9832\n",
      "Epoch 10/25\n",
      "12879/12879 [==============================] - 13s 978us/step - loss: 0.0598 - accuracy: 0.9852\n",
      "Epoch 11/25\n",
      "12879/12879 [==============================] - 11s 889us/step - loss: 0.0599 - accuracy: 0.9845\n",
      "Epoch 12/25\n",
      "12879/12879 [==============================] - 14s 1ms/step - loss: 0.0512 - accuracy: 0.9874\n",
      "Epoch 13/25\n",
      "12879/12879 [==============================] - 12s 900us/step - loss: 0.0488 - accuracy: 0.9877\n",
      "Epoch 14/25\n",
      "12879/12879 [==============================] - 12s 895us/step - loss: 0.0431 - accuracy: 0.9904\n",
      "Epoch 15/25\n",
      "12879/12879 [==============================] - 11s 892us/step - loss: 0.0480 - accuracy: 0.9880\n",
      "Epoch 16/25\n",
      "12879/12879 [==============================] - 11s 881us/step - loss: 0.0428 - accuracy: 0.9896\n",
      "Epoch 17/25\n",
      "12879/12879 [==============================] - 12s 937us/step - loss: 0.0369 - accuracy: 0.9915\n",
      "Epoch 18/25\n",
      "12879/12879 [==============================] - 12s 906us/step - loss: 0.0459 - accuracy: 0.9893\n",
      "Epoch 19/25\n",
      "12879/12879 [==============================] - 12s 914us/step - loss: 0.0388 - accuracy: 0.9901\n",
      "Epoch 20/25\n",
      "12879/12879 [==============================] - 12s 929us/step - loss: 0.0367 - accuracy: 0.9918\n",
      "Epoch 21/25\n",
      "12879/12879 [==============================] - 12s 908us/step - loss: 0.0339 - accuracy: 0.9922\n",
      "Epoch 22/25\n",
      "12879/12879 [==============================] - 11s 882us/step - loss: 0.0404 - accuracy: 0.9902\n",
      "Epoch 23/25\n",
      "12879/12879 [==============================] - 13s 990us/step - loss: 0.0341 - accuracy: 0.9920\n",
      "Epoch 24/25\n",
      "12879/12879 [==============================] - 12s 949us/step - loss: 0.0285 - accuracy: 0.9933\n",
      "Epoch 25/25\n",
      "12879/12879 [==============================] - 11s 892us/step - loss: 0.0277 - accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x283cbea3b88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compiling and Fitting the Model\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Save the created Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the Model \n",
    "\n",
    "model.save('model_sudoku.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
